# Gemma 3:4B

Gemma 3:4B is a fast and remarkably efficient language model developed by Google, built upon the same cutting-edge technology behind the Gemini models. It is designed to be the ultimate local partner for creative writers, offering a perfect balance between performance and accessibility.

## Why Choose Gemma 3:4B?

- **Creativity & Speed:** Ideal for rapid brainstorming, dialogue generation, and plot exploration.
- **Privacy First:** Operates 100% locally on your PC. Your stories, notes, and drafts never leave your machine.
- **Deep Context:** Features a **128k context window**, allowing it to "remember" complex narratives and detailed world-building across large documents.
- **Completely Free:** No subscriptions or per-use fees.

## System Requirements

Gemma 3:4B is optimized for consumer hardware, making it accessible to most writers.

| Component | Minimum | Recommended |
| :--- | :--- | :--- |
| **RAM** | 8 GB | 16 GB or higher |
| **GPU** | Integrated Graphics | NVIDIA GeForce RTX 3060 or better |
| **OS** | Windows / Linux / macOS | Latest version for driver support |

## How to Get Gemma 3:4B

SammyAI uses **Ollama** to run Gemma 3 locally. Follow these steps to set it up:

1. **Install Ollama:** Download and install the application from [ollama.com](https://ollama.com/).
2. **Download the Model:** Open your terminal (Command Prompt, PowerShell, or Terminal) and run:
   ```bash
   ollama run gemma3:4b
   ```
3. **Connect to SammyAI:** Once the model is downloaded, verify that Ollama is running in your system tray. SammyAI will automatically detect the model when you select it from the dropdown.

---

> [!TIP]
> **Need help with Ollama?**
> For detailed troubleshooting and advanced configuration (like running as a service), check out the [Official Ollama Documentation](https://docs.ollama.com/).
